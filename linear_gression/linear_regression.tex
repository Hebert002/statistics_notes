%-*- coding: UTF-8 -*-
% linear_gression.tex
% 线性回归
\documentclass[UTF8]{ctexart}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\geometry{a4paper,centering,scale=0.8}
\usepackage{float}
\usepackage[format=hang,font=small,textfont=it]{caption}
\usepackage[nottoc]{tocbibind}
\newenvironment{myquote}
{\begin{quote}\kaishu\zihao{-5}}
	{\end{quote}}

\title{\heiti 线性回归}
\author{\kaishu Herbert002}
\date{\today}

\newtheorem{thm}{定理}

\bibliographystyle{plain}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		尽量通俗易懂，基于理工科本科数学水平的线性回归笔记.
	\end{abstract}
	
	\tableofcontents
	
	\section{线性回归的通俗理解}
	线性回归的通俗理解.
	
	\section{线性回归的简要历史}
	高尔顿爵士关于身高体重的实验.
	
	\section{一元线性回归}
	我们先考虑一元线性回归.
	
	\section{多元线性回归}
	多元线性回归是指回归变量个数大于等于2的线性回归.
	
	回归平方和服从卡方分布的证明
	
	\begin{equation}
		\begin{aligned}
			SSR & = \sum_{i=1}^{n} {(\hat{y_{i}} - \overline{y})^2} \\
			    & = [\boldsymbol{\hat{y}} - \boldsymbol{1} \overline{y}]^T [\boldsymbol{\hat{y}} - \boldsymbol{1} \overline{y}] \\
			    & = [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{y} - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{y}]^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{y} - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{y}] \\
			    & = \boldsymbol{y}^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T ]^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \boldsymbol{y} \\
		\end{aligned}
	\end{equation}

    上式中，$ \boldsymbol{1} \in \mathbb{R}^{n} $，是一个元素均为1的列向量. 响应变量均值可以表示为 $ \overline{y} = (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{y} $.
    
    接下来证明 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T $ 是对称矩阵.
    
    \begin{equation}
    	\begin{aligned}
    		[\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1}  \boldsymbol{1}^T]^T 
    		& = [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T]^T - [\boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1}  \boldsymbol{1}^T]^T \\
    		& = \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1}  \boldsymbol{1}^T
    	\end{aligned}
    \end{equation}
    得证.
    
    证明 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T $ 是幂等的.
    
    如果说矩阵 $ A $ 是幂等的，则有 $ \boldsymbol{A} = \boldsymbol{A} \boldsymbol{A} = \dots = \boldsymbol{A}^n $
    
    证明 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T $ 的幂等性，需要先证明如下结论.
    
    
    \begin{equation}
        \begin{aligned}
            \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{1} & = \boldsymbol{1} \\
            \boldsymbol{1}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T & = \boldsymbol{1}^T
        \end{aligned}
    \end{equation}

    $ \boldsymbol{X} \in \mathbb{R}^{n \times (k + 1)} $ 可以分解为 $ \boldsymbol{X} = [\boldsymbol{1} \  \boldsymbol{X}_R] $ ，其中 $ \boldsymbol{X}_{R} \in \mathbb{R}^{n \times k} $ ，则有 
   
    \begin{equation}
        \begin{aligned}
            \boldsymbol{X}^T \boldsymbol{X} 
            = \begin{bmatrix}
                \boldsymbol{1}^T \\
                \boldsymbol{X}_R^T
            \end{bmatrix} \begin{bmatrix}
                \boldsymbol{1} \  \boldsymbol{X}_R
            \end{bmatrix} = \begin{bmatrix}
                \boldsymbol{1}^T \boldsymbol{1} & \boldsymbol{1}^T \boldsymbol{X}_R \\
                \boldsymbol{X}_R^T \boldsymbol{1} & \boldsymbol{X}_R^T \boldsymbol{X}_R
            \end{bmatrix}
        \end{aligned}
    \end{equation}

    显然，$ \boldsymbol{X}^T \boldsymbol{X} $ 是对称矩阵，其逆矩阵也是对称矩阵，假设其为
    
    \begin{equation}
    	(\boldsymbol{X}^T \boldsymbol{X})^{-1} = \begin{bmatrix}
    		a & \boldsymbol{b}^T \\
    		\boldsymbol{b} & \boldsymbol{C}
    	\end{bmatrix}
    \end{equation}

    其中，$ a \in \mathbb{R} $ 是个标量，$ \boldsymbol{b} \in \mathbb{R}^k $ ， $ \boldsymbol{C} \in \mathbb{R}^{k \times k} $ ，则有
    
    \begin{equation}
    	\begin{aligned}
    		\boldsymbol{X}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} & = \begin{bmatrix}
    			\boldsymbol{1}^T \boldsymbol{1} & \boldsymbol{1}^T \boldsymbol{X}_R \\
    			\boldsymbol{X}_R^T \boldsymbol{1} & \boldsymbol{X}_R^T \boldsymbol{X}_R
    		\end{bmatrix} \begin{bmatrix}
    		    a & \boldsymbol{b}^T \\
    		    \boldsymbol{b} & \boldsymbol{C}
    		\end{bmatrix} \\
    	    & = \begin{bmatrix}
    	    	\boldsymbol{1}^T \boldsymbol{1} a + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{b} & \boldsymbol{1}^T \boldsymbol{1} \boldsymbol{b}^T + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{C} \\
    	    	\boldsymbol{X}_R^T \boldsymbol{1} a + \boldsymbol{X}_R^T \boldsymbol{X}_R \boldsymbol{b} & \boldsymbol{X}_R^T \boldsymbol{1} \boldsymbol{b}^T + \boldsymbol{X}_R^T \boldsymbol{X}_R \boldsymbol{C}
    	    \end{bmatrix} \\
            & = \begin{bmatrix}
            	1 & \boldsymbol{0}^T \\
            	\boldsymbol{0} & \boldsymbol{I}_k
            \end{bmatrix}
    	\end{aligned}
    \end{equation}

    上式中 $ \boldsymbol{0} \in \mathbb{R}^k $ ， $ \boldsymbol{I}_k \in \mathbb{R}^{k \times k} $ 是单位矩阵. 观察最后一个等号前后矩阵的第一行，显然有
    
    \begin{equation}
    	\begin{aligned}
    		\boldsymbol{1}^T \boldsymbol{1} a + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{b} & = 1 \\
    		\boldsymbol{1}^T \boldsymbol{1} \boldsymbol{b}^T + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{C} & = \boldsymbol{0}^T
    	\end{aligned}
    \end{equation}

    再看 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T $ ，如下
    
    \begin{equation}
    	\begin{aligned}
    		\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{1} & = \begin{bmatrix}
    			\boldsymbol{1} \  \boldsymbol{X}_R 
    		\end{bmatrix} \begin{bmatrix}
    		    a & \boldsymbol{b}^T \\
    		    \boldsymbol{b} & \boldsymbol{C}
    	    \end{bmatrix} \begin{bmatrix}
    	        \boldsymbol{1}^T \\
    	        \boldsymbol{X}_R^T
            \end{bmatrix} \boldsymbol{1} \\
            & = \begin{bmatrix}
                a \boldsymbol{1} + \boldsymbol{X}_R \boldsymbol{b} &  \boldsymbol{1} \boldsymbol{b}^T + \boldsymbol{X}_R \boldsymbol{C}
            \end{bmatrix} \begin{bmatrix}
                \boldsymbol{1}^T \\
                \boldsymbol{X}_R^T
            \end{bmatrix} \boldsymbol{1} \\
            & = \begin{bmatrix}
            	a \boldsymbol{1} \boldsymbol{1}^T + \boldsymbol{X}_R \boldsymbol{b} \boldsymbol{1}^T + \boldsymbol{1} \boldsymbol{b}^T \boldsymbol{X}_R^T + \boldsymbol{X}_R \boldsymbol{C} \boldsymbol{X}_R^T
            \end{bmatrix} \boldsymbol{1} \\
            & = a \boldsymbol{1} \boldsymbol{1}^T \boldsymbol{1} + \boldsymbol{X}_R \boldsymbol{b} \boldsymbol{1}^T \boldsymbol{1} + \boldsymbol{1} \boldsymbol{b}^T \boldsymbol{X}_R^T \boldsymbol{1} + \boldsymbol{X}_R \boldsymbol{C} \boldsymbol{X}_R^T \boldsymbol{1}
    	\end{aligned}
    \end{equation}
    
    观察上式最后一个等号的右边，第一项中 $ \boldsymbol{1}^T \boldsymbol{1} \in \mathbb{R} $ ，第三项中 $ \boldsymbol{b}^T \boldsymbol{X}_R^T \boldsymbol{1} $ 都是标量，标量的转置是其本身，再结合(7)式，第一项和第三项的和
    
    \begin{equation}
    	\begin{aligned}
    		a \boldsymbol{1} \boldsymbol{1}^T \boldsymbol{1} + \boldsymbol{1} \boldsymbol{b}^T \boldsymbol{X}_R^T \boldsymbol{1} & = a (\boldsymbol{1}^T \boldsymbol{1}) \boldsymbol{1} + (\boldsymbol{b}^T \boldsymbol{X}_R^T \boldsymbol{1}) \boldsymbol{1} \\
    		& = a (\boldsymbol{1}^T \boldsymbol{1}) \boldsymbol{1} + (\boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{b}) \boldsymbol{1} \\
    		& = [a (\boldsymbol{1}^T \boldsymbol{1}) + (\boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{b})] \boldsymbol{1} \\
    		& = \boldsymbol{1}
    	\end{aligned}
    \end{equation}

    结合(7)式，再看第二项和第四项的和
    
    \begin{equation}
    	\begin{aligned}
    		\boldsymbol{X}_R \boldsymbol{b} \boldsymbol{1}^T \boldsymbol{1} + \boldsymbol{X}_R \boldsymbol{C} \boldsymbol{X}_R^T \boldsymbol{1} & = [[\boldsymbol{X}_R \boldsymbol{b} \boldsymbol{1}^T \boldsymbol{1} + \boldsymbol{X}_R \boldsymbol{C} \boldsymbol{X}_R^T \boldsymbol{1}]^T]^T \\
    		& = [\boldsymbol{1}^T \boldsymbol{1} \boldsymbol{b}^T \boldsymbol{X}_R^T + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{C}^T \boldsymbol{X}_R^T]^T \\
    		& = [(\boldsymbol{1}^T \boldsymbol{1} \boldsymbol{b}^T + \boldsymbol{1}^T \boldsymbol{X}_R \boldsymbol{C}^T) \boldsymbol{X}_R^T]^T \\
    		& =  [\boldsymbol{0}^T \boldsymbol{X}_R^T]^T \\
    		& = \boldsymbol{0}
       	\end{aligned}
    \end{equation}

    回看(8)式，可得 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{1} = \boldsymbol{1} $ ，同理可得 $ \boldsymbol{1}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T = \boldsymbol{1}^T $ . 推导过程中，需要注意矩阵和向量的维数.
    
    接下来就有
    
    \begin{equation}
    	\begin{aligned}
    		& \quad \  [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T]^2 \\
    		& = [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \\
    		& = \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \\
    		& \quad - \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T + \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \\
    		& = \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T - \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T + \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T \\
    		& = \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T
    	\end{aligned}
    \end{equation}
    
    结合(2)式的结论，(1)式可继续推导为
    
    \begin{equation}
    	\begin{aligned}
    		SSR & = \sum_{i=1}^{n} {(\hat{y_{i}} - \overline{y})^2} \\
    		& = \boldsymbol{y}^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T ]^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{y} - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \boldsymbol{y} \\
    		& = \boldsymbol{y}^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T ] [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \boldsymbol{y} \\
    		& = \boldsymbol{y}^T [\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \boldsymbol{y}
    	\end{aligned}
    \end{equation}

    至此，上面已经证明了 $ \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T $ 是一个幂等的实对称矩阵. 接下来，将其简单表示为 $ \boldsymbol{Q} $ ， 则有
    
    \begin{equation}
    	SSR = \boldsymbol{y}^T \boldsymbol{Q} \boldsymbol{y}
    \end{equation}
    

    因为 $ \boldsymbol{Q} \in \mathbb{R}^{n \times n} $ 是实对称矩阵，所以其可以正交对角化，即存在正交矩阵$ \boldsymbol{P} \in \mathbb{R}^{n \times n} $ ，使得
    
    \begin{equation}
        \boldsymbol{P}^{-1} \boldsymbol{Q} \boldsymbol{P} = \boldsymbol{P}^T \boldsymbol{Q} \boldsymbol{P} = \boldsymbol{\varLambda} 
    \end{equation}

    其中，$ \boldsymbol{\varLambda} \in \mathbb{R}^{n \times n} $ 是实对角矩阵，对角线上的元素是 $ \boldsymbol{Q} $ 的 $ n $ 个特征值. 所以有
    
    \begin{equation}
    	\begin{aligned}
    		SSR & = \boldsymbol{y}^T \boldsymbol{Q} \boldsymbol{y} \\
    		& =  \boldsymbol{y}^T \boldsymbol{P} \boldsymbol{\varLambda} \boldsymbol{P}^T \boldsymbol{y} \\
    		& = (\boldsymbol{P}^T \boldsymbol{y})^T \boldsymbol{\varLambda} (\boldsymbol{P}^T \boldsymbol{y})
    	\end{aligned}
    \end{equation}

    又因为 $ \boldsymbol{Q} $ 是等幂矩阵，所以有
    
    \begin{equation}
    	\begin{aligned}
    	    \boldsymbol{\varLambda}^2 & = \boldsymbol{P}^T \boldsymbol{Q} \boldsymbol{P} \boldsymbol{P}^T \boldsymbol{Q} \boldsymbol{P} \\
    	    & = \boldsymbol{P}^T \boldsymbol{Q}^2 \boldsymbol{P} \\
    	    & = \boldsymbol{P}^T \boldsymbol{Q} \boldsymbol{P} \\
    	    & = \boldsymbol{\varLambda}
    	\end{aligned}
    \end{equation}

    可见 $ \boldsymbol{\varLambda} $ 也是等幂的. 如果一个对角矩阵是等幂的，其对角元素要么是1，要么是0（可自行证明）.
    
    用$ p_{ij} $ 表示 $ \boldsymbol{P} $ 第 $ i $ 行第 $ j $ 列的元素. $ \boldsymbol{P}^T \boldsymbol{y} \in \mathbb{R}^n $ 的第i个元素可以表示为 $ \sum_{j=1}^{n}{p_{ji} y_{j}} $ ，带入(15)式，可得
    
    \begin{equation}
    	\begin{aligned}
    		SSR & = (\boldsymbol{P}^T \boldsymbol{y})^T \boldsymbol{\varLambda} (\boldsymbol{P}^T \boldsymbol{y}) \\
    		& = \begin{bmatrix}
    		    \sum_{j=1}^{n}{p_{j1} y_{j}} \ \sum_{j=1}^{n}{p_{j2} y_{j}} \dots \sum_{j=1}^{n}{p_{jn} y_{j}}
    		\end{bmatrix} \begin{bmatrix}
    		    \lambda_1 & & & \\
    		    & \lambda_2 & & \\
    		    & & \ddots & \\
    		    & & & \lambda_n
    	    \end{bmatrix} \begin{bmatrix}
    	        \sum_{j=1}^{n}{p_{j1} y_{j}} \\
    	        \sum_{j=1}^{n}{p_{j2} y_{j}} \\
    	        \vdots \\
    	        \sum_{j=1}^{n}{p_{jn} y_{j}}
            \end{bmatrix} \\
            & = \sum_{i=1}^{n}{\lambda_i (\sum_{j=1}^{n}{p_{ji} y_{j}})^2} \\
            & = \sum_{i=1}^{m}{(\sum_{j=1}^{n}{p_{ji} y_{j}})^2}
        \end{aligned}
    \end{equation}

    上式中， $ m $ 是对角矩阵 $ \boldsymbol{\varLambda} $ 对角元素为1的个数.
    
    
    当 $ \boldsymbol{\beta} = \boldsymbol{0}$ 时，$ \boldsymbol{y} = \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{\epsilon} = \boldsymbol{\epsilon} $ ，则有
    
    \begin{equation}
    	\begin{aligned}
    		SSR & = \sum_{i=1}^{m}{(\sum_{j=1}^{n}{p_{ji} y_{j}})^2}
    		& = \sum_{i=1}^{m}{(\sum_{j=1}^{n}{p_{ji} \epsilon_{j}})^2}
    	\end{aligned}
    \end{equation}

    则有
    
    \begin{equation}
        \begin{aligned}
        	& \epsilon_{j} \sim \mathcal{N}(0, \sigma^2) \\
        	\Downarrow & \\
        	& p_{ji} \epsilon_{j} \sim \mathcal{N}(0, p_{ji}^2 \sigma^2) \\
        	\Downarrow & \\
        	& \sum_{j=1}^{n}{p_{ji} \epsilon_{j}} \sim \mathcal{N}(0, \sum_{i=1}^{n}p_{ji}^2 \sigma^2) \\
        	\Downarrow & \\
        	& \sum_{j=1}^{n}{p_{ji} \epsilon_{j}} \sim \mathcal{N}(0, \sigma^2 \sum_{i=1}^{n}p_{ji}^2) \\
        	\Downarrow & \quad (\sum_{i=1}^{n}p_{ji}^2 = 1) \\
        	& \sum_{j=1}^{n}{p_{ji} \epsilon_{j}} \sim \mathcal{N}(0, \sigma^2) \\
        	\Downarrow & \\
        	& \frac{1}{\sigma} \sum_{j=1}^{n}{p_{ji} \epsilon_{j}} \sim \mathcal{N}(0, 1) \\
        	\Downarrow & \\ 
        	& \sum_{i=1}^{m}{(\frac{1}{\sigma} \sum_{j=1}^{n}{p_{ji} \epsilon_{j}})^2} \sim \mathcal{\chi}^2(m) \\
        	\Downarrow & \\
        	& \frac{1}{\sigma^2} SSR \sim \mathcal{\chi}^2(m)
        \end{aligned}
    \end{equation}

    上面倒数第二个推导 $ (\Downarrow) $ 需要证明 $ \frac{1}{\sigma} \sum_{j=1}^{n}{p_{ji} \epsilon_{j}} $ 和 $ \frac{1}{\sigma} \sum_{j=1}^{n}{p_{jl} \epsilon_{j}} $ 之间的独立性，如下
    
    \begin{equation}
    	\begin{aligned}
    	    Cov(\frac{1}{\sigma} \sum_{j=1}^{n}{p_{ji} \epsilon_{j}}, \frac{1}{\sigma} \sum_{j=1}^{n}{p_{jl} \epsilon_{j}}) & = \frac{1}{\sigma^2} Cov(\sum_{j=1}^{n}{p_{ji} \epsilon_{j}}, \sum_{j=1}^{n}{p_{jl} \epsilon_{j}}) \\
    	    & = \frac{1}{\sigma^2} \sum_{j=1}^{n} \sum_{h=1}^{n} Cov(p_{ji} \epsilon_{j}, p_{hl} \epsilon_{h}) \\
    	    & = \frac{1}{\sigma^2} \sum_{j=1}^{n} \sum_{h=1}^{n} p_{ji} p_{hl} Cov(\epsilon_{j}, \epsilon_{h}) \\
    	    & = \frac{1}{\sigma^2} \sum_{j=1}^{n} \sum_{h=1}^{n} p_{ji} p_{hl} \cdot 0 \\
    	    & = 0
    	\end{aligned}
    \end{equation}

    上式中，因为 $ \epsilon_i $ 之间相互独立，所以 $ Cov(\epsilon_i, \epsilon_j) = 0 $ . 协方差为0的正态分布，相互独立. 独立性得证. 

    最后，来看看上面这个卡方分布的自由度 $ m $ ，到底是多少. 上面已经说过，是对角矩阵 $ \boldsymbol{\varLambda} $ 的对角元素要么是1，要么是0， $ m $  是1的个数，也就是说，$ m $ 也是对角矩阵 $ \boldsymbol{\varLambda} $ 的迹，所以
    
    \begin{equation}
        \begin{aligned}
            m & = trace(\boldsymbol{\varLambda}) \\
            & = trace(\boldsymbol{P}^T \boldsymbol{Q} \boldsymbol{P}) \\
            & = trace(\boldsymbol{P} \boldsymbol{P}^T \boldsymbol{Q}) \\
            & = trace(\boldsymbol{Q}) \\
            & = trace[\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T - \boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \\
            & = trace[\boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1} \boldsymbol{X}^T] - trace[\boldsymbol{1}  (\boldsymbol{1}^T \boldsymbol{1})^{-1} \boldsymbol{1}^T] \\
            & = trace[\boldsymbol{X}^T \boldsymbol{X} (\boldsymbol{X}^T \boldsymbol{X})^{-1}] - trace[\boldsymbol{1}^T \boldsymbol{1} (\boldsymbol{1}^T \boldsymbol{1})^{-1}] \\
            & = trace(\boldsymbol{I}_{k + 1}) - trace(\boldsymbol{I}_1) \\
            & = k + 1 - 1 \\
            & = k
        \end{aligned}
    \end{equation}

    上式中的 $ k $ 就是回归模型中回归变量的个数. 推导过程中使用到了矩阵迹的性质。
    
    到此，我们已经基本完整地证明了回归平方和 $ \frac{1}{\sigma^2} SSR $ 服从自由度为 $ k $ 的卡方分布，用数学表达式表示为
    
    \begin{equation}
    	\frac{1}{\sigma^2} SSR \sim \mathcal{\chi}^2(k)
    \end{equation}


    
    
    

    
    
    
    \section{附录}
    定理一
    
    实对称矩阵 $ \boldsymbol{A} \in \mathbb{R}^{n \times n} $ 必定正交相似于实对角矩阵 $ \boldsymbol{\varLambda} $ ，即存在正交矩阵 $ \boldsymbol{P} $ ，使得 $ \boldsymbol{P}^{-1} \boldsymbol{A} \boldsymbol{P} = \boldsymbol{P}^T \boldsymbol{A} \boldsymbol{P} = \boldsymbol{\varLambda} $ ，其中 $ \boldsymbol{\varLambda} $ 对角线上的元素是 $ \boldsymbol{A} $ 的 $ n $ 个特征值.
    
    证明可请参考线性代数的教材.
    
    定理二
    
    矩阵迹的运算有如下性质：
    
    \begin{equation}\
    	\begin{aligned}
    	    & trace(\boldsymbol{A} \boldsymbol{B}) = trace(\boldsymbol{B} \boldsymbol{A}) \\
    	    & trace(\boldsymbol{A} + \boldsymbol{B}) = trace(\boldsymbol{A}) + trace(\boldsymbol{B}) \\
    	    & trace(c \boldsymbol{A}) = c \cdot trace(\boldsymbol{A})
    	\end{aligned}
    \end{equation}
    
	
	
	
%	\bibliography{math}
	
\end{document}
